{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg19 for cluster.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1t5N82AGKsFsmcaOVpChrTLCFuoTRxJrU",
      "authorship_tag": "ABX9TyPsHxkSXS/CFgY28fJk/4f+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a07646b386ad4077bca8d0d90e1bac15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f0e822d5227459aaeb76a0452dddd9c",
              "IPY_MODEL_46d8aaca9dd14f7bbbc875122819b1ab",
              "IPY_MODEL_56271b9767e6496db0301d883d560047"
            ],
            "layout": "IPY_MODEL_1e6bffd0589447a994267596383e74a4"
          }
        },
        "5f0e822d5227459aaeb76a0452dddd9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb968fe86d7548948b5e7dfff10c2657",
            "placeholder": "​",
            "style": "IPY_MODEL_9bb22a61514a42228f19b256be3eed39",
            "value": ""
          }
        },
        "46d8aaca9dd14f7bbbc875122819b1ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75af6e51dfc344ffa40d7abea9ae7731",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b121d59d58824ccb8112876edc0c0a85",
            "value": 170498071
          }
        },
        "56271b9767e6496db0301d883d560047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd1d6641a84049f49544c7a837912ef9",
            "placeholder": "​",
            "style": "IPY_MODEL_b018b134ef8240b6907161d3a9d78025",
            "value": " 170499072/? [00:03&lt;00:00, 56463580.73it/s]"
          }
        },
        "1e6bffd0589447a994267596383e74a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb968fe86d7548948b5e7dfff10c2657": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bb22a61514a42228f19b256be3eed39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75af6e51dfc344ffa40d7abea9ae7731": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b121d59d58824ccb8112876edc0c0a85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd1d6641a84049f49544c7a837912ef9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b018b134ef8240b6907161d3a9d78025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumankmaiti/All-in-one/blob/main/vgg19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "import torch.utils.data as data\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "from sklearn import decomposition\n",
        "from sklearn import manifold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from tqdm.notebook import tqdm, trange\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import copy\n",
        "import random\n",
        "import time\n"
      ],
      "metadata": {
        "id": "TI-eUfkWTK-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"We'll also set the random seeds.\"\"\"\n",
        "\n",
        "### Defining the Model \n",
        "\n",
        "class VGG(nn.Module):\n",
        "    def __init__(self, features, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.features = features\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(7)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, output_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        h = x.view(x.shape[0], -1)\n",
        "        x = self.classifier(h)\n",
        "        # x = F.softmax(x, dim=-1)\n",
        "\n",
        "        return x, h\n"
      ],
      "metadata": {
        "id": "Xj3eQqC0TXky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Next up is calculating the `features` for each VGG configuration.\"\"\"\n",
        "\n",
        "vgg11_config = [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
        "\n",
        "vgg13_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512,\n",
        "                512, 'M']\n",
        "\n",
        "vgg16_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512,\n",
        "                'M', 512, 512, 512, 'M']\n",
        "\n",
        "vgg19_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512,\n",
        "                512, 512, 'M', 512, 512, 512, 512, 'M']\n"
      ],
      "metadata": {
        "id": "m5kCCyx2UKVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vgg_layers(config, batch_norm):\n",
        "\n",
        "    layers = []\n",
        "    in_channels = 3\n",
        "\n",
        "    for c in config:\n",
        "        assert c == 'M' or isinstance(c, int)\n",
        "        if c == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, c, kernel_size=3, stride=1, padding=1)\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(c), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = c\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\"\"\"Now, let's get the `features` for the VGG11 architecture, with batch normalization.\"\"\"\n",
        "\n",
        "vgg19_layers = get_vgg_layers(vgg19_config, batch_norm=False)\n",
        "vgg19_layers\n",
        "\"\"\"We can print them out and ensure they are the same as the \"A\" configuration of the VGG configuration table.\"\"\"\n",
        "\n",
        "print(vgg19_layers)\n",
        "with open('log_vgg19_imagenet_lr_change.txt', 'a') as f:\n",
        "        f.write(str(vgg19_layers))\n",
        "        f.write('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JRBgilxUN2Y",
        "outputId": "e564eeb5-2f97-4c44-e7e2-649369072a33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (3): ReLU(inplace=True)\n",
            "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (6): ReLU(inplace=True)\n",
            "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): ReLU(inplace=True)\n",
            "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (11): ReLU(inplace=True)\n",
            "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): ReLU(inplace=True)\n",
            "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (15): ReLU(inplace=True)\n",
            "  (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (17): ReLU(inplace=True)\n",
            "  (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (20): ReLU(inplace=True)\n",
            "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (22): ReLU(inplace=True)\n",
            "  (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (24): ReLU(inplace=True)\n",
            "  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (26): ReLU(inplace=True)\n",
            "  (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (29): ReLU(inplace=True)\n",
            "  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (31): ReLU(inplace=True)\n",
            "  (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (33): ReLU(inplace=True)\n",
            "  (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (35): ReLU(inplace=True)\n",
            "  (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"We can then pass these `features` to our base VGG module to get our VGG11 model.\"\"\"\n",
        "\n",
        "OUTPUT_DIM = 10\n",
        "\n",
        "model = VGG(vgg19_layers, OUTPUT_DIM)\n",
        "\n",
        "print(model)\n",
        "with open('log_vgg19_imagenet_lr_change.txt', 'a') as f:\n",
        "        f.write(str(model))\n",
        "        f.write('\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28rV2snzWjFg",
        "outputId": "bc6916c1-622b-4b46-a53a-40f10d84500a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (24): ReLU(inplace=True)\n",
            "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): ReLU(inplace=True)\n",
            "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (33): ReLU(inplace=True)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): ReLU(inplace=True)\n",
            "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=7)\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_size = [224, 224]\n",
        "pretrained_means = [0.485, 0.456, 0.406]\n",
        "pretrained_stds = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "                           transforms.Resize(pretrained_size),\n",
        "                           transforms.RandomRotation(5),\n",
        "                           transforms.RandomHorizontalFlip(0.5),\n",
        "                           transforms.RandomCrop(pretrained_size, padding=10),\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize(mean=pretrained_means,\n",
        "                                                std=pretrained_stds)\n",
        "                       ])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "                           transforms.Resize(pretrained_size),\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize(mean=pretrained_means,\n",
        "                                                std=pretrained_stds)\n",
        "                       ])"
      ],
      "metadata": {
        "id": "puMVepIAYvjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \"\"\"...then create the validation split...\"\"\"\n",
        "# ROOT = 'dataset'\n",
        "\n",
        "# train_data = datasets.CIFAR10(ROOT,\n",
        "#                               train=True,\n",
        "#                               download=True,\n",
        "#                               transform=train_transforms)\n",
        "\n",
        "# test_data = datasets.CIFAR10(ROOT,\n",
        "#                              train=False,\n",
        "#                              download=True,\n",
        "#                              transform=test_transforms)\n",
        "\n",
        "# VALID_RATIO = 0.9\n",
        "\n",
        "# n_train_examples = int(len(train_data) * VALID_RATIO)\n",
        "# n_valid_examples = len(train_data) - n_train_examples\n",
        "\n",
        "# train_data, valid_data = data.random_split(train_data,\n",
        "#                                            [n_train_examples, n_valid_examples])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "a07646b386ad4077bca8d0d90e1bac15",
            "5f0e822d5227459aaeb76a0452dddd9c",
            "46d8aaca9dd14f7bbbc875122819b1ab",
            "56271b9767e6496db0301d883d560047",
            "1e6bffd0589447a994267596383e74a4",
            "cb968fe86d7548948b5e7dfff10c2657",
            "9bb22a61514a42228f19b256be3eed39",
            "75af6e51dfc344ffa40d7abea9ae7731",
            "b121d59d58824ccb8112876edc0c0a85",
            "fd1d6641a84049f49544c7a837912ef9",
            "b018b134ef8240b6907161d3a9d78025"
          ]
        },
        "id": "BQmGif01Y_Qa",
        "outputId": "05754e49-b103-4120-863e-9faf25333468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to dataset/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a07646b386ad4077bca8d0d90e1bac15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/cifar-10-python.tar.gz to dataset\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "train_data = torchvision.datasets.ImageFolder(\"/content/drive/MyDrive/train_last_10/\", transform= train_transforms)\n",
        "VALID_RATIO = 0.8\n",
        "\n",
        "n_train_examples = int(len(train_data) * VALID_RATIO)\n",
        "n_valid_examples = len(train_data) - n_train_examples\n",
        "\n",
        "train_data, valid_data = data.random_split(train_data,\n",
        "                                           [n_train_examples, n_valid_examples])\n"
      ],
      "metadata": {
        "id": "ZpHmyla5tC8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"...and ensure the validation data uses the test transforms.\"\"\"\n",
        "\n",
        "valid_data = copy.deepcopy(valid_data)\n",
        "valid_data.dataset.transform = test_transforms\n",
        "\n",
        "\"\"\"Again, we'll print out the number of examples in each split to ensure they are correct.\"\"\"\n",
        "\n",
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "#print(f'Number of testing examples: {len(test_data)}')\n",
        "with open('log_vgg19_imagenet_lr_change.txt', 'a') as f:\n",
        "        f.write(f'Number of training examples: {len(train_data)}\\n')\n",
        "        f.write(f'Number of validation examples: {len(valid_data)}\\n')\n",
        "#        f.write(f'Number of testing examples: {len(test_data)}\\n')\n",
        "        f.write('\\n') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qz59mKE3WuM5",
        "outputId": "d318a850-ad69-4e0c-e65f-1699f1d82630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 10400\n",
            "Number of validation examples: 2600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"As the model is ~5x the size of the AlexNet model from the previous notebook we use a smaller batch size so it can fit on reasonably sized GPUs. This should be increased if we have access to GPUs with more memory in order to speed up training.\"\"\"\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "train_iterator = data.DataLoader(train_data,\n",
        "                                 shuffle=True,\n",
        "                                 batch_size=BATCH_SIZE)\n",
        "\n",
        "valid_iterator = data.DataLoader(valid_data,\n",
        "                                 batch_size=BATCH_SIZE)\n",
        "\n",
        "#test_iterator = data.DataLoader(test_data,\n",
        "#                                batch_size=BATCH_SIZE)\n"
      ],
      "metadata": {
        "id": "_VJOsy0daLaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"### Training the Model\n",
        "\n",
        "We'll use the learning rate finder as used in previous notebooks. Generally when using a pre-trained model the learning rate used will be considerably lower.\n",
        "\n",
        "First, we'll set up the optimizer with the initial learning rate that is much lower than we expect to use. Then we define the `device` to place our model on our GPU, if we have one. Next we define the `criterion` (loss function) and place the model and criterion on our device.\n",
        "\"\"\"\n",
        "\n",
        "START_LR = 0.0001\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=START_LR, betas=(0.9, 0.999), weight_decay = 0.0005)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = nn.DataParallel(model)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "vOSWTpbHaGoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Now all of the set-up is done, the rest of the notebook is pretty standard from here on out.\n",
        "\n",
        "We create a function to calculate accuracy...\n",
        "\"\"\"\n",
        "\n",
        "def calculate_accuracy(y_pred, y):\n",
        "    # print(y_pred)\n",
        "    # print(y.shape[0])\n",
        "    top_pred = y_pred.argmax(1)\n",
        "    # print(top_pred)\n",
        "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "    acc = correct.float() / y.shape[0]   \n",
        "    # print(correct)\n",
        "    # print(acc)\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "ehXDMInvaTKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"...create a function that implements a training loop...\"\"\"\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, device):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for (x, y) in iterator:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        # print(y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        y_pred, _ = model(x)\n",
        "        # print(_)\n",
        "\n",
        "        loss = criterion(y_pred, y)\n",
        "\n",
        "        acc = calculate_accuracy(y_pred, y)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    # print(epoch_loss, epoch_acc, len(iterator))\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
      ],
      "metadata": {
        "id": "CtXSClU8aXLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"...create a function that performs an evaluation loop...\"\"\"\n",
        "\n",
        "def evaluate(model, iterator, criterion, device):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for (x, y) in iterator:\n",
        "\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            model.to(device)\n",
        "            y_pred, _ = model(x)\n",
        "\n",
        "            loss = criterion(y_pred, y)\n",
        "\n",
        "            acc = calculate_accuracy(y_pred, y)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
      ],
      "metadata": {
        "id": "G1vvIUqEap0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"...and a helper function to tell us how long an epoch takes.\"\"\"\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n"
      ],
      "metadata": {
        "id": "lnAPO32WavVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Finally, we train our model.\"\"\"\n",
        "\n",
        "EPOCHS = 100\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    start_time = time.monotonic()\n",
        "\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, device)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'vgg19_imagenet_lr_change.pt')\n",
        "\n",
        "    end_time = time.monotonic()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "    with open('log_vgg19_imagenet_lr_change.txt', 'a') as f:\n",
        "        f.write(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "        f.write(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "        f.write(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "        f.write('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "LwDN4cPGa3aZ",
        "outputId": "c71a6a27-249a-49ed-863a-c4f16b720b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Epoch Time: 59m 47s\n",
            "\tTrain Loss: 2.303 | Train Acc: 9.83%\n",
            "\t Val. Loss: 2.303 |  Val. Acc: 10.58%\n",
            "Epoch: 02 | Epoch Time: 14m 17s\n",
            "\tTrain Loss: 2.303 | Train Acc: 9.48%\n",
            "\t Val. Loss: 2.303 |  Val. Acc: 9.38%\n",
            "Epoch: 03 | Epoch Time: 14m 5s\n",
            "\tTrain Loss: 2.303 | Train Acc: 9.74%\n",
            "\t Val. Loss: 2.303 |  Val. Acc: 9.50%\n",
            "Epoch: 04 | Epoch Time: 13m 53s\n",
            "\tTrain Loss: 2.303 | Train Acc: 9.82%\n",
            "\t Val. Loss: 2.303 |  Val. Acc: 9.50%\n",
            "Epoch: 05 | Epoch Time: 14m 12s\n",
            "\tTrain Loss: 2.303 | Train Acc: 9.58%\n",
            "\t Val. Loss: 2.303 |  Val. Acc: 9.50%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-164ac08b4662>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-e334a010d562>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mepoch_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Our test accuracy is a little lower at ~92%, but is still higher than the ~75% achieved by the AlexNet model in the previous tutorial notebook.\"\"\"\n",
        "\n",
        "model.load_state_dict(torch.load('vgg19_imagenet_lr_change.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, valid_iterator, criterion, device)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n",
        "with open('log_vgg19_imagenet_lr_change.txt', 'a') as f:\n",
        "        f.write(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n",
        "        f.write('\\n')"
      ],
      "metadata": {
        "id": "lt8kJMyDbFvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fw3871lWRKem"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, iterator):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "    probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for (x, y) in iterator:\n",
        "\n",
        "            x = x.to(device)\n",
        "\n",
        "            y_pred, _ = model(x)\n",
        "\n",
        "            y_prob = F.softmax(y_pred, dim=-1)\n",
        "\n",
        "            images.append(x.cpu())\n",
        "            labels.append(y.cpu())\n",
        "            probs.append(y_prob.cpu())\n",
        "\n",
        "    images = torch.cat(images, dim=0)\n",
        "    labels = torch.cat(labels, dim=0)\n",
        "    probs = torch.cat(probs, dim=0)\n",
        "\n",
        "    return images, labels, probs\n",
        "\n",
        "images, labels, probs = get_predictions(model, valid_iterator)\n",
        "\n",
        "\"\"\"...then get the predicted labels for each image...\"\"\"\n",
        "\n",
        "pred_labels = torch.argmax(probs, 1)\n",
        "\n",
        "print(\"prdected lebels:\",pred_labels)\n",
        "print(\"original lebels:\",labels)\n",
        "with open('log_vgg19_imagenet_lr_change.txt', 'a') as f:\n",
        "        f.write(\"prdected lebels:\",pred_labels)\n",
        "        f.write(\"original lebels:\",labels)\n",
        "        f.write('\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of target with class indices\n",
        "loss = nn.CrossEntropyLoss()\n",
        "input = torch.randn(3, 5, requires_grad=True)\n",
        "print(input)\n",
        "target = torch.empty(3, dtype=torch.long).random_(5)\n",
        "print(target)\n",
        "output = loss(input, target)\n",
        "print(output)\n",
        "output.backward()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_6uQQHbto8E",
        "outputId": "727768d4-be82-4fea-f607-9a83c516e757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4448, -0.4471, -0.7386, -0.0355, -1.1138],\n",
            "        [-0.7687, -1.1237,  0.7376, -0.8181,  0.7374],\n",
            "        [ 1.1422, -0.3587, -0.7909, -0.4120, -1.1980]], requires_grad=True)\n",
            "tensor([0, 2, 4])\n",
            "tensor(1.7892, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    }
  ]
}